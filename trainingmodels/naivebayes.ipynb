{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Import Statements </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score,classification_report, ConfusionMatrixDisplay\n",
    "from string import punctuation\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as tf\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame()\n",
    "train=pd.DataFrame()\n",
    "test = pd.read_csv('test.csv', \n",
    "                    delimiter=',', encoding='ISO-8859-1')\n",
    "test.drop(columns=['textID','Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'])\n",
    "train = pd.read_csv('train.csv', \n",
    "                    delimiter=',', encoding='ISO-8859-1')\n",
    "train.drop(columns=['textID','selected_text','Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)'])\n",
    "stuff_to_be_removed = list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Text processing code</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/asammohamed/sentiment-ana-with-svm-knn-trian-91-test-85\n",
    "def textprocessing(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()                                                          # converting all uppercase letters to lowercase\n",
    "    text = re.sub(r\"https\\S+|www\\S+|https\\S+\",\" \",text,flags=re.MULTILINE)       # removing all links from dataset\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)       \n",
    "    text = re.sub(r'\\@\\w+|\\#',\" \",text)                                          # removing # and @ symbols from dataset\n",
    "    text = re.sub(r'[^\\w\\s\\`]',\" \",text)                                         # removing other symbols like ^ except '\n",
    "    text_tokens = word_tokenize(text) \n",
    "    lem = SnowballStemmer(\"english\")\n",
    "    text = [lem.stem(word) for word in text_tokens if not word in stuff_to_be_removed] \n",
    "    text1 = \" \".join(text)\n",
    "    \n",
    "    return text1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Naive Bayes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27481,)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train=train['sentiment'].astype(str)\n",
    "Y_true=np.array(test['sentiment'].astype(str))\n",
    "Y_test=[]\n",
    "X_train = train['text'].astype(str).apply(textprocessing)\n",
    "X_test = test['text'].astype(str).apply(textprocessing)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Vectorization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = tf()\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()\n",
    "#print(X_train.shape)\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb= GaussianNB()\n",
    "Y_test=gnb.fit(X_train, Y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nan       0.00      0.00      0.00      1281\n",
      "    negative       0.32      0.78      0.45      1001\n",
      "     neutral       0.47      0.12      0.19      1430\n",
      "    positive       0.16      0.29      0.21      1103\n",
      "\n",
      "    accuracy                           0.26      4815\n",
      "   macro avg       0.24      0.30      0.21      4815\n",
      "weighted avg       0.24      0.26      0.20      4815\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sakee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sakee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sakee\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_true, Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
